input {
	kafka {
		topic_id => "beats"
		auto_commit_interval_ms => "1000"
		group_id  => "logstash"
		codec => "json"
		consumer_threads => 2
		zk_connect => "{{ zk_host }}:{{ zk_port }}"
	}
}

filter {
	mutate {
		gsub => [ "message", "[\\]", "" ]
	}

	grok {
		patterns_dir => ["patterns"]
		match => { "message" => "%{NGINX_ACCESS}"}
		overwrite => [ "host" ]
		remove_field => [ "message" , "source" , "offset" ]
	}
	
	if [http_x_forwarded_for] !~ "-" {
		mutate {
			split => { "http_x_forwarded_for" => "," }
			add_field => { "client_ip" => "%{[http_x_forwarded_for][0]}"}
		}
	} else {
        mutate {
            add_field => { "client_ip" => "%{remote_addr}"}
        }
    }

	date {
		match => [ "time_local" , "dd/MMM/yyyy:HH:mm:ss Z" ]
	}

	geoip {
		source => "client_ip"
	}

	useragent {
		source => "http_user_agent"
		target => "user_agent"
	}
}

output {
	elasticsearch {
    	hosts => ["{{ es_host }}:{{ es_port }}"]
        index => "logstash-%{type}-%{+YYYY.MM.dd}"
        flush_size => 20000
        idle_flush_time => 10
    }
	#stdout { codec => rubydebug }
}
